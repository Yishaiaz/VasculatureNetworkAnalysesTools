#!/bin/bash

################################################################################################
### sbatch configuration parameters must start with #SBATCH and must precede any other commands.
### To ignore, just add another # - like so: ##SBATCH
################################################################################################

#SBATCH --partition main			### specify partition name where to run a job. short: 7 days limit; gtx1080: 7 days; debug: 2 hours limit and 1 job at a time
#SBATCH --time 0-12:59:00			### limit the time of job running. Make sure it is not greater than the partition time limit!! Format: D-H:MM:SS
#SBATCH --job-name GIN-experiments-non-fixed-num-layers			### name of the job
#SBATCH --output job-%J.out			### output log for running job - %J for job number
#SBATCH --gpus=1 ### number of GPUs. Choosing type e.g.: #SBATCH --gpus=gtx_1080:1 , or rtx_2080, or rtx_3090 . Allocating more than 1 requires the IT team’s permission
##SBATCH --tasks=1  # 1 process – use for processing of few programs concurrently in a job (with srun). Use just 1 otherwise

# Note: the following 4 lines are commented out
#SBATCH --mail-user=yishaiaz@post.bgu.ac.il	### user's email for sending job status messages
#SBATCH --mail-type=BEGIN,END,FAIL			### conditions for sending the email. ALL,BEGIN,END,FAIL, REQUEU, NONE
#SBATCH --mem=16G				### ammount of RAM memory

export LD_LIBRARY_PATH=/home/yishaiaz/.conda/envs/torch_geo230_env/lib:$LD_LIBRARY_PATH

### Print some data to output file ###
echo `date`
echo -e "\nSLURM_JOBID:\t\t" $SLURM_JOBID
echo -e "SLURM_JOB_NODELIST:\t" $SLURM_JOB_NODELIST "\n\n"

### Start your code below ####
###SSD
export CWD=$PWD
export SLURM_SCRATCH_DIR=/scratch/${SLURM_JOB_USER}/${SLURM_JOBID}
echo -e "SLURM_SCRATCH_DIR:\t" $SLURM_SCRATCH_DIR "\n\n"

cp ~/GBVasculatureGraphsAnalysis/BrainVasculatureGraphData/torch_data_graph_annotated_subgraph_with_labels $SLURM_SCRATCH_DIR/torch_data_graph_annotated_subgraph_with_labels

###/SSD
module load anaconda				### load anaconda module (must be present when working with conda environments)
source activate /home/yishaiaz/anaconda3/envs/torch_geo230_env				### activate a conda environment, replace my_env with your conda environment

export SCRIPT_NAME=GINExperimentsManager.py
export SCRIPT_PATH=~/VasculatureNetworkAnalysesTools/NetworkUtilities/${SCRIPT_NAME}
echo "Working from $CWD"
echo "started with ${SCRIPT_NAME} python script at ${SCRIPT_PATH}"
python ${SCRIPT_PATH} --job_id ${SLURM_JOBID}   				### execute python script
echo "done with ${SCRIPT_NAME} python script"
###SSD
cp -r $SLURM_SCRATCH_DIR $SLURM_SUBMIT_DIR
echo -e "COPIED TO SLURM_SUBMIT_DIR:\t" $SLURM_SUBMIT_DIR "\n\n"
###/SSD
